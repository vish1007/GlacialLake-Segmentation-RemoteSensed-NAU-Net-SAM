```markdown
# Glacier Lake Segmentation from Remote Sensing Data using UNet and SAM

This repository provides a pipeline for glacial lake segmentation using multi-band remote sensing data and deep learning models such as NAU-Net and SAM (Segment Anything Model). The data is processed from Landsat imagery and DEMs, enhanced with NDWI, NDSI, and slope bands.

---

## ğŸ“ Project Structure

```

glacier-lake-segmentation/
â”‚
â”œâ”€â”€ data/                    # Dataset setup and preprocessing instructions
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ models/                  # Model definitions
â”‚   â”œâ”€â”€ nau\_net.py
â”‚   â”œâ”€â”€ sam\_model.py
â”‚
â”œâ”€â”€ training/                # Training scripts
â”‚   â”œâ”€â”€ train\_nau\_net.py
â”‚   â”œâ”€â”€ train\_sam.py
â”‚
â”œâ”€â”€ inference/              # Inference scripts
â”‚   â”œâ”€â”€ infer\_nau\_net.py
â”‚   â”œâ”€â”€ infer\_sam.py
â”‚
â”œâ”€â”€ utils/                  # Helper functions
â”‚   â”œâ”€â”€ metrics.py
â”‚   â”œâ”€â”€ data\_loader.py
â”‚   â”œâ”€â”€ visualization.py
â”‚
â”œâ”€â”€ notebooks/              # Jupyter notebooks (EDA, comparison, visualization)
â”‚   â””â”€â”€ results\_comparison.ipynb
â”‚
â”œâ”€â”€ results/                # Outputs or checkpoints (optional)
â”‚
â”œâ”€â”€ requirements.txt        # Required Python packages
â”œâ”€â”€ README.md               # Project overview and usage
â”œâ”€â”€ .gitignore              # Ignore patterns
â”œâ”€â”€ LICENSE                 # License file (e.g., MIT)

````

---

## ğŸ”§ Setup Instructions

### 1. Clone the repository

```bash
git clone https://github.com/your-username/glacier-lake-segmentation.git
cd glacier-lake-segmentation
````

### 2. Create and activate a virtual environment (recommended)

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ’¡ Note on Project Imports

Python allows importing sibling directories using relative or absolute imports as long as the project root is in the Python path.

For example, `training/train_nau_net.py` can import from `utils` like this:

```python
from utils.metrics import compute_iou
from utils.data_loader import get_dataloader
```

To run the training script properly, execute it from the **project root**:

```bash
python training/train_nau_net.py
```

Avoid running the script from within the `training/` folder directly.

---

## ğŸš€ How to Run

### 1. Train NAU-Net

```bash
python training/train_nau_net.py
```

### 2. Train SAM model with UNet-generated masks as prompts

```bash
python training/train_sam.py
```

### 3. Inference using trained models

```bash
python inference/infer_nau_net.py
python inference/infer_sam.py
```

---

## ğŸ“¦ Dataset

Detailed instructions for data preparation, including:

* Downloading Landsat and DEM data
* Computing NDWI, NDSI, slope
* Creating patches
* Band stacking and formatting

See [`data/README.md`](data/README.md) for full preprocessing steps.

---

## ğŸ“„ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

---

## âœï¸ Citation

If you use this code or dataset in your research, please cite:

> Chen, F., et al. â€œAnnual 30 m dataset for glacial lakes in high mountain Asia from 2008 to 2017.â€ Earth System Science Data (2021).

---

## ğŸ¤ Contributions

Pull requests and suggestions are welcome. Please open an issue for major changes.

```

Let me know if you'd like to include example model outputs, Hugging Face deployment steps, or visualizations!
```
